# ディレクトリスキャン並列化ベンチマーク

## 概要

このプロジェクトは、Goでディレクトリスキャンの並列化効果を測定するベンチマークツールです。
異なるディレクトリ構造と並列化戦略での性能を比較します。

### 測定対象

- **ディレクトリ構造**
  - 浅い構造: 100ディレクトリ × 100ファイル = 10,000ファイル
  - 深い構造: 10×10×10×10 の4階層 = 10,000ファイル

- **並列化戦略**
  - ディレクトリベース: 各ワーカーが1つのディレクトリを処理
  - 再帰的タスク分割: 深さ優先で動的にタスクを分割

- **並列度**
  - 1, 2, 4, 8 ワーカー

## 必要環境

- Go 1.16以上
- Linux/macOS/Windows

## セットアップ

```bash
# プロジェクトの初期化
go mod init dir-scan-benchmark

# 依存関係の取得（標準ライブラリのみ使用）
go mod tidy
```

## 実行方法

### 開発モード（小規模データ）

開発・テスト時は小規模なデータセットで動作確認できます：

```bash
go run main.go dev
```

- 浅い構造: 4×4 = 16ファイル
- 深い構造: 2×2×2×2 = 32ファイル（最深層のみにファイル）

### 本番モード（大規模データ）

実際のベンチマーク測定時：

```bash
go run main.go
```

- 浅い構造: 100×100 = 10,000ファイル
- 深い構造: 10×10×10×10 = 10,000ファイル

## 出力結果

### コンソール出力

```
ディレクトリスキャン並列化ベンチマーク
モード: 本番
CPU数: 8
=====================================

shallow構造のテストデータを作成中...
期待されるファイル数: 10000

deep構造のテストデータを作成中...
期待されるファイル数: 10000

===== ベンチマーク実行 =====

構造: shallow

戦略: directory-based
  ワーカー数 1 でベンチマーク実行中... 完了 (0.150s, speedup: 1.00x)
  ワーカー数 2 でベンチマーク実行中... 完了 (0.080s, speedup: 1.88x)
  ワーカー数 4 でベンチマーク実行中... 完了 (0.045s, speedup: 3.33x)
  ワーカー数 8 でベンチマーク実行中... 完了 (0.030s, speedup: 5.00x)

[以下省略]
```

### CSV出力

実行結果は自動的にCSVファイルに保存されます：

- ファイル名: `benchmark/benchmark_results_YYYYMMDD_HHMMSS.csv`
- 内容: 構造、戦略、ワーカー数、実行時間、ファイル数、ディレクトリ数、速度向上率

## 結果の見方

### 速度向上率（Speedup）

- 1ワーカーの実行時間を基準とした相対的な性能向上
- 理想値: ワーカー数と同じ（例: 4ワーカーで4.0x）
- 実際はオーバーヘッドにより理想値より低くなる

### 構造による違い

- **浅い構造**: 多数の独立したディレクトリ → 並列化しやすい
- **深い構造**: 階層的な依存関係 → 並列化の効果が限定的

### 戦略による違い

- **directory-based**: 浅い構造で効果的
- **recursive-task**: 深い構造で効果的

## 並列化戦略の詳細

### 1. ディレクトリベース戦略（Directory-Based）

**方式**
- トップレベルのディレクトリを各ワーカーに均等に分配
- 各ワーカーは割り当てられたディレクトリを独立して処理
- ディレクトリ内のサブディレクトリは再帰的に処理

**実装の特徴**
```go
// ディレクトリをワーカー数で分割
for i, dir := range dirs {
    workerID := i % numWorkers
    // ワーカーIDに対応するディレクトリを割り当て
}
```

**メリット**
- 実装がシンプルで理解しやすい
- 各ワーカーの作業が明確に分離されている
- 浅い構造では負荷分散が効果的
- メモリ使用量が予測可能

**デメリット**
- トップレベルのディレクトリ数が少ない場合、ワーカーが遊ぶ可能性
- ディレクトリサイズが不均一な場合、負荷の偏りが発生
- 深い構造では並列性が制限される

**適用場面**
- 多数の独立したディレクトリがある場合
- 各ディレクトリのサイズが比較的均一な場合
- メモリ使用量を抑えたい場合

### 2. 再帰的タスク分割戦略（Recursive-Task）

**方式**
- ディレクトリをタスクとして動的にキューに追加
- ワーカーはキューからタスクを取得して処理
- サブディレクトリを発見したら新しいタスクとしてキューに追加

**実装の特徴**
```go
// タスクキューとワーカープール
taskChan := make(chan string, 1000)
// ワーカーは動的にタスクを取得
for path := range taskChan {
    // サブディレクトリを新しいタスクとして追加
    taskChan <- subdirPath
}
```

**メリット**
- 動的な負荷分散により、全ワーカーを効率的に活用
- 深い構造でも高い並列性を維持
- ディレクトリサイズの偏りに対して柔軟に対応
- アイドル状態のワーカーが自動的に新しいタスクを取得

**デメリット**
- 実装が複雑（同期処理、デッドロック対策が必要）
- タスクキューのメモリオーバーヘッド
- 小さなタスクが多い場合、コンテキストスイッチのオーバーヘッド
- デバッグが困難

**適用場面**
- 深い階層構造のディレクトリツリー
- ディレクトリサイズが不均一な場合
- 最大限の並列性が必要な場合
- CPU数が多い環境

### 性能特性の比較

| 特性 | Directory-Based | Recursive-Task |
|------|----------------|----------------|
| 実装の複雑さ | 低 | 高 |
| メモリ使用量 | 低 | 中〜高 |
| 負荷分散 | 静的 | 動的 |
| 浅い構造での性能 | 優秀 | 良好 |
| 深い構造での性能 | 良好 | 優秀 |
| スケーラビリティ | 中 | 高 |

## プロファイリング

### 実行時のプロファイル取得

CPUプロファイル:

```bash
go run main.go -cpuprofile=prof/cpu.prof
```

メモリプロファイル:

```bash
go run main.go -memprofile=prof/mem.prof
```

両方のプロファイル:

```bash
go run main.go -cpuprofile=prof/cpu.prof -memprofile=prof/mem.prof
```

### プロファイルの解析

CPUプロファイルの解析:

```bash
go tool pprof prof/cpu.prof
```

メモリプロファイルの解析:

```bash
go tool pprof prof/mem.prof
```

## トラブルシューティング

### ファイル数が一致しない

- ファイルシステムのエラーを確認
- ディスク容量を確認

### 性能が期待通りでない

- ファイルシステムのキャッシュが影響している可能性
- 実行前にキャッシュをクリア: `sync && echo 3 > /proc/sys/vm/drop_caches` (Linux)

### CPU使用率が低い

- I/Oボトルネックの可能性
- SSDでの実行を推奨

## カスタマイズ

### 設定の変更

`main.go`の`getConfig`関数で設定を調整：

```go
func getConfig(isDev bool) Config {
    // カスタム設定を追加
}
```

### 新しい並列化戦略の追加

1. 新しいScannerインターフェースの実装を作成
2. `runBenchmark`関数に戦略を追加
3. `strategies`配列に追加

## ディレクトリ構造

```
.
├── main.go           # メインプログラム
├── cpu_monitor.go    # CPU使用率モニタリング（オプション）
├── benchmark/        # ベンチマーク結果（.gitignore）
├── prof/            # プロファイルデータ（.gitignore）
└── README.md        # このファイル
```

## ライセンス

MIT License
